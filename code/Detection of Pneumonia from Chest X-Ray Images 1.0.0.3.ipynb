{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Detection of Pneumonia from Chest X-Ray Images using Convolutional Neural Network, \n",
    "                   and Transfer Learning.\n",
    "Description      : 1. Detected Pneumonia from Chest X-Ray images using Custom Deep Convololutional Neural Network and by                         retraining pretrained model “InceptionV3” with 5856 images of X-ray (1.15GB).\n",
    "                   2. For retraining removed output layers, freezed first few layers and fine-tuned model for \n",
    "                      two new label classes (Pneumonia and Normal).\n",
    "                   3. With Custom Deep Convololutional Neural Network attained testing accuracy 89.53% and loss 0.41.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.3\n",
    "Last Update      : 12.16.2018\n",
    "Comments         : Please use Anaconda editor for convenience of visualization.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Chest X-Ray Images (Pneumonia)\n",
    "Dataset Link     : <a href=https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia>Chest X-Ray Images (Pneumonia) Dataset (Kaggle)</a>\n",
    "                 : <a href=https://data.mendeley.com/datasets/rscbjbr9sj/2>Chest X-Ray Images (Pneumonia) Dataset (Original Dataset)</a>\n",
    "Original Paper   : <a href=https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5>Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning</a>\n",
    "                   (Daniel S. Kermany, Michael Goldbaum, Wenjia Cai, M. Anthony Lewis, Huimin Xia, Kang Zhang)\n",
    "                   https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Chest X-Ray Images (Pneumonia)\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 5856 (1.15 Gigabyte (GB))\n",
    "                          Training   : 5216 (1.07 Gigabyte (GB))\n",
    "                          Validation : 320  (42.8 Megabyte (MB))\n",
    "                          Testing    : 320  (35.4 Megabyte (MB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3 && Custom Deep Convolutional Neural Network\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>For Custom Deep Convolutional Neural Network : </b>\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 64\n",
    "Number of Epochs        : 30\n",
    "Training Time           : 2 Hours\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy (F-1) Score    : 89.53%\n",
    "Loss                    : 0.41\n",
    "Precision               : 88.37%\n",
    "Recall (Pneumonia)      : 95.48% (For positive class)\n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Performance Report\n",
    "<pre>\n",
    "Summary\n",
    "--------------------------\n",
    "Loss     : 0.41  \n",
    "Accuracy : 89.53%\n",
    "\n",
    "Derived Report\n",
    "--------------------------\n",
    "Precision     : 88.37%\n",
    "Recall        : 95.48%\n",
    "F1-Score      : 91.79%\n",
    "        \n",
    "--------------------------------------------------------------------------------\n",
    "Report for Model File:  2018-12-15 22-32-00/10-val_acc-0.96-val_loss-0.11.hdf5\n",
    "--------------------------------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "--------------------------------------------------------------------------------\n",
    "      Normal       0.91      0.79      0.85       121\n",
    "   Pneumonia       0.88      0.95      0.92       199\n",
    "--------------------------------------------------------------------------------\n",
    "   micro avg       0.89      0.89      0.89       320\n",
    "   macro avg       0.90      0.87      0.88       320\n",
    "weighted avg       0.90      0.89      0.89       320\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import inspect\n",
    "import gc\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, GlobalAveragePooling1D, GlobalAveragePooling2D, Flatten, BatchNormalization, Dense\n",
    "\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam, SGD , RMSprop\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "K.image_data_format()\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory, if directory exists removes if remove parameter is set to True \n",
    "def create_directory(directory_path, remove=False):\n",
    "    if remove and os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Removes directory, if directory exists \n",
    "def remove_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def clear_directory(directory_path):\n",
    "    dirs_files = os.listdir(directory_path)\n",
    "    \n",
    "    for item in dirs_files:\n",
    "#         item_path = os.path.join(directory_path, item)\n",
    "        item_path = directory_path+ item\n",
    "        \n",
    "        try:\n",
    "            if os.path.isfile(item_path):\n",
    "                os.unlink(item_path)\n",
    "            elif os.path.isdir(item_path): \n",
    "                shutil.rmtree(item_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_empty_folders(path, removeRoot=True):\n",
    "    if not os.path.isdir(path):\n",
    "        return\n",
    "    \n",
    "    # remove empty subfolders\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    if len(files):\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(path, f)\n",
    "            \n",
    "            if os.path.isdir(fullpath):\n",
    "                remove_empty_folders(fullpath)\n",
    "\n",
    "    # if folder empty, delete it\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    if len(files) == 0 and removeRoot:\n",
    "        print(\"Removing empty folder:\", path)\n",
    "        os.rmdir(path)\n",
    "        \n",
    "        \n",
    "def dir_file_count(directory):\n",
    "    return sum([len(files) for r, d, files in os.walk(directory)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print date and time for given type of representation\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        return 'Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())\n",
    "    if x==2:    \n",
    "        return 'Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now())\n",
    "    if x==3:  \n",
    "        return 'Date now: %s' % datetime.datetime.now()\n",
    "    if x==4:  \n",
    "        return 'Date today: %s' % datetime.date.today()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a integer for degugging\n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reset_subplot_params(nrows, ncols, dpi):\n",
    "    subplot_params = {}\n",
    "    subplot_params[\"nrows\"] = nrows\n",
    "    subplot_params[\"ncols\"] = ncols\n",
    "\n",
    "    subplot_params[\"figsize_col\"] = subplot_params[\"ncols\"]*2.5\n",
    "    subplot_params[\"figsize_row\"] = subplot_params[\"nrows\"]*2.5\n",
    "    subplot_params[\"dpi\"] = dpi\n",
    "    subplot_params[\"facecolor\"] = 'w'\n",
    "    subplot_params[\"edgecolor\"] = 'k'\n",
    "    subplot_params[\"subplot_kw\"] = {'xticks': [], 'yticks': []}\n",
    "    subplot_params[\"axes.titlesize\"] = 'small'\n",
    "    subplot_params[\"hspace\"] = 0.5\n",
    "    subplot_params[\"wspace\"] = 0.3\n",
    "    \n",
    "    return subplot_params\n",
    "\n",
    "def get_reset_plot_params(figsize=(15, 5), title=\"\", xlabel =\"\", ylabel=\"\", legends=[], title_fontsize = 18, label_fontsize = 14, image_file_name=\"\", save = False, dpi=100, update_image=True):\n",
    "    plot_params = {}\n",
    "    \n",
    "    plot_params[\"figsize\"] = figsize\n",
    "    \n",
    "    plot_params[\"title\"] = title\n",
    "    \n",
    "    plot_params[\"xlabel\"] = xlabel\n",
    "    plot_params[\"ylabel\"] = ylabel\n",
    "    \n",
    "    plot_params[\"legends\"] = legends \n",
    "    \n",
    "    plot_params[\"title_fontsize\"] = title_fontsize\n",
    "    plot_params[\"axes.titlesize\"] = \"small\"\n",
    "    plot_params[\"label_fontsize\"] = label_fontsize\n",
    "    \n",
    "    plot_params[\"image_file_name\"] = image_file_name\n",
    "    plot_params[\"save\"] = save\n",
    "    plot_params[\"update_image\"] = update_image\n",
    "    \n",
    "    plot_params[\"subplot\"] = None\n",
    "    return plot_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_image_by_category(image_dir, image_count_per_category):\n",
    "    classes = os.listdir(image_dir)\n",
    "    class_count = len(classes)\n",
    "\n",
    "    image_file_paths = {}\n",
    "    \n",
    "    for i in range(class_count):\n",
    "        subdir_path = image_dir+\"/\"+classes[i]\n",
    "        subdir_files = os.listdir(subdir_path)\n",
    "\n",
    "        subdir_file_count = len(subdir_files)\n",
    "\n",
    "        subdir_file_mem = {}\n",
    "        \n",
    "        subdir_file_index = -1\n",
    "        \n",
    "        image_file_paths[classes[i]] = []\n",
    "        \n",
    "        for j in range(image_count_per_category):\n",
    "            while subdir_file_index in subdir_file_mem:\n",
    "                subdir_file_index = random.randint(0, subdir_file_count-1)\n",
    "                \n",
    "            subdir_file_mem[subdir_file_index] = 1\n",
    "            \n",
    "            subdir_file_name = subdir_files[subdir_file_index]\n",
    "            subdir_file_path = subdir_path+ \"/\" + subdir_file_name\n",
    "\n",
    "            image_file_paths[classes[i]].append(subdir_file_path)\n",
    "            \n",
    "    return image_file_paths\n",
    "\n",
    "\n",
    "def get_fig_axs(subplot_params):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=subplot_params[\"nrows\"], ncols=subplot_params[\"ncols\"], \n",
    "        figsize=(subplot_params[\"figsize_col\"], subplot_params[\"figsize_row\"]),\n",
    "        dpi=subplot_params[\"dpi\"], facecolor=subplot_params[\"facecolor\"], \n",
    "        edgecolor=subplot_params[\"edgecolor\"], subplot_kw=subplot_params[\"subplot_kw\"])\n",
    "        \n",
    "    return fig, axs\n",
    "    \n",
    "\n",
    "def plot_sample_image(image_file_paths, plot_params, subplot_params, update_image=True):\n",
    "    fig, axs = get_fig_axs(subplot_params)\n",
    "\n",
    "    plt.rcParams.update({'axes.titlesize': plot_params[\"axes.titlesize\"]})\n",
    "    plt.subplots_adjust(hspace=subplot_params[\"hspace\"], wspace=subplot_params[\"wspace\"])\n",
    "\n",
    "\n",
    "    i=0\n",
    "    for img_filepath in image_file_paths:\n",
    "        img = cv2.imread(img_filepath, 1)\n",
    "        plt.title(img_filepath.split(\"/\")[-1])\n",
    "        plt.subplot(subplot_params[\"nrows\"], subplot_params[\"ncols\"], i+1)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        i=i+1\n",
    "        \n",
    "    if plot_params[\"update_image\"] and os.path.exists(plot_params[\"image_file_name\"]):\n",
    "        os.remove(plot_params[\"image_file_name\"])  \n",
    "    if plot_params[\"save\"]:\n",
    "        fig.savefig(plot_params[\"image_file_name\"], dpi=plot_params[\"dpi\"])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def show_class_sample_images(directory, image_count_per_category=5, save=False, dpi=100, update_image=False):\n",
    "    class_count = len(os.listdir(directory))\n",
    "    print(\"Number of Class: \", class_count)\n",
    "    sample_img_by_class = select_image_by_category(directory, image_count_per_category)\n",
    "    for class_name in sample_img_by_class:\n",
    "        plot_params = get_reset_plot_params(image_file_name=\"img.png\", save = save, dpi=dpi, update_image=update_image)\n",
    "        subplot_params = get_reset_subplot_params(nrows=1, ncols=image_count_per_category, dpi=dpi)\n",
    "        print(\"%s%s%s\"%(\"-\"*55, name_correct(class_name), \"-\"*55))\n",
    "        plot_sample_image(sample_img_by_class[class_name], plot_params, subplot_params)\n",
    "        print(\"\")\n",
    "    print(\"%s%s%d%s\"%(\"-\"*55, \"All Class Printed:\", class_count, \"-\"*55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of files in each subdirectory of a directory\n",
    "def subdirectory_file_count(master_directory):\n",
    "    subdirectories = os.listdir(master_directory)\n",
    "    subdirectory_count = len(subdirectories)\n",
    "\n",
    "    subdirectory_names = []\n",
    "    subdirectory_file_counts = []\n",
    "\n",
    "    for subdirectory in subdirectories:\n",
    "        current_directory = os.path.join(master_directory, subdirectory)\n",
    "        file_count = len(os.listdir(current_directory))\n",
    "        subdirectory_names.append(subdirectory)\n",
    "        subdirectory_file_counts.append(file_count)\n",
    "    \n",
    "    return subdirectory_names, subdirectory_file_counts\n",
    "         \n",
    "    \n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, plot_property):\n",
    "    if plot_property['subplot']:\n",
    "        plt.subplot(plot_property['subplot'])\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(plot_property['title'], fontsize=plot_property['title_fontsize'])\n",
    "    plt.xlabel(plot_property['xlabel'], fontsize=plot_property['label_fontsize'])\n",
    "    plt.ylabel(plot_property['ylabel'], fontsize=plot_property['label_fontsize'])\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, plot_property):\n",
    "    dir_name, dir_file_count = subdirectory_file_count(master_directory)\n",
    "    x = [name_correct(i) for i in dir_name]\n",
    "    # x = dir_name\n",
    "    y = dir_file_count\n",
    "    bar_plot(x, y, plot_property)\n",
    "    \n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, plot_property):\n",
    "    plt.figure(figsize=plot_property['figsize'])\n",
    "    \n",
    "    title = plot_property['title']\n",
    "    plot_property['title'] = title + \" (Training)\"\n",
    "    subplot_no = plot_property['subplot'] \n",
    "\n",
    "    count_bar_plot(training_dir, plot_property)\n",
    "    \n",
    "    \n",
    "    plot_property['title'] = title + \" (Validation)\"\n",
    "    plot_property['subplot'] = subplot_no+1\n",
    "    count_bar_plot(validation_dir, plot_property)\n",
    "    \n",
    "    \n",
    "    plot_property['title'] = title + \" (Testing)\"\n",
    "    plot_property['subplot'] = subplot_no + 2\n",
    "    count_bar_plot(testing_dir, plot_property)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    if model:\n",
    "        try:\n",
    "            del model\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint = None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "reset_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/josezea/Documents/GitHub/pneumonia-detector/code\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/output/figures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d6e5953efbb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/output/figures'"
     ]
    }
   ],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory + r\"train\"\n",
    "validation_dir = input_directory + r\"val\"\n",
    "testing_dir = input_directory + r\"test\"\n",
    "\n",
    "\n",
    "figure_directory = r\"data/output/figures\"\n",
    "\n",
    "figure_directory = \"data/output/figures\"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)\n",
    "    \n",
    "    \n",
    "file_name_pred_batch = figure_directory+r\"/result\"\n",
    "file_name_pred_sample = figure_directory+r\"/sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_class_sample_images(training_dir, image_count_per_category=5, save=False, dpi=100, update_image=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = get_reset_plot_params()\n",
    "\n",
    "plot_params['figsize'] = (18,4)\n",
    "\n",
    "plot_params['title_fontsize'] = 13\n",
    "plot_params['label_fontsize'] = 10\n",
    "\n",
    "plot_params['title'] = \"Number of Cases\"\n",
    "\n",
    "plot_params['subplot'] = 131\n",
    "\n",
    "show_train_val_test(training_dir, validation_dir, testing_dir, plot_params)\n",
    "classes = os.listdir(training_dir)\n",
    "classes = [name_correct(i) for i in classes]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Image Preprocessing/ Augmentation/ Transformation for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "\n",
    "# target_size = (299, 299)\n",
    "# color_mode = \"rgb\"\n",
    "\n",
    "\n",
    "rescale = 1./255\n",
    "target_size = (150, 150)\n",
    "batch_size = 163\n",
    "class_mode = \"categorical\"\n",
    "# class_mode = \"binary\"\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=rescale,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=rescale)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=dir_file_count(validation_dir),\n",
    "    shuffle = False)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=rescale)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    testing_dir,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=dir_file_count(testing_dir),\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "def get_weight(y):\n",
    "    class_weight_current =  class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "    return class_weight_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training Files Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = get_weight(train_generator.classes)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model_dir = output_directory + r\"models/\"\n",
    "main_log_dir = output_directory + r\"logs/\"\n",
    "\n",
    "\n",
    "clear_directory(main_log_dir)\n",
    "remove_empty_folders(main_model_dir, False)\n",
    "\n",
    "\n",
    "model_dir = main_model_dir + time.strftime('%Y-%m-%d %H-%M-%S') + \"/\"\n",
    "log_dir = main_log_dir + time.strftime('%Y-%m-%d %H-%M-%S')\n",
    "\n",
    "create_directory(model_dir, remove=True)\n",
    "create_directory(log_dir, remove=True)\n",
    "\n",
    "model_file = model_dir + \"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "reset_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Settting Callbacks at \", date_time(1))\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    model_file, \n",
    "    monitor='val_acc', \n",
    "    save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    batch_size=batch_size,\n",
    "    update_freq = 'batch')\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    cooldown=2,\n",
    "    min_lr=0.0000000001,\n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# callbacks = [checkpoint, tensorboard]\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "print(\"Set Callbacks at \", date_time(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding=\"same\", input_shape=(3,150,150)))\n",
    "    model.add(Conv2D(16, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\", input_shape=(3,150,150)))\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
    "    model.add(Conv2D(96, (3, 3), padding=\"valid\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 , activation='softmax'))\n",
    "\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "def get_model():    \n",
    "    \n",
    "#     base_model = InceptionV3(weights=None, include_top=False)\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "#     x = Dropout(0.5)(x)\n",
    "    \n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "#     x = Dense(512, activation='relu')(x)\n",
    "#     # x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "# #     predictions = Dense(2, activation='sigmoid')(x) \n",
    "    predictions = Dense(2, activation='softmax')(x) \n",
    "    \n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "        \n",
    "#     for layer in model.layers[:249]:\n",
    "#         layer.trainable = False\n",
    "#     for layer in model.layers[249:]:\n",
    "#         layer.trainable = True\n",
    "        \n",
    "    \n",
    "    model.summary()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Fine-Tuning Base Model-InceptionV3 for Fine-Tuning with New Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting Base Model\", date_time(1))\n",
    "# model = get_model()\n",
    "model = get_conv_model()\n",
    "# model = keras.models.load_model(\"data/output/models/2018-12-15 00-26-45/13-val_acc-0.70-val_loss-0.58.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Trainning Model\", date_time(1))\n",
    "\n",
    "\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "\n",
    "\n",
    "# lr = 0.00001\n",
    "# optimizer=optimizers.Adam(lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "optimizer=optimizers.Adam()\n",
    "loss='categorical_crossentropy'\n",
    "metrics=['accuracy']\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps, \n",
    "    class_weight=class_weight)\n",
    "\n",
    "print(\"Completed Model Trainning\", date_time(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = 'Epoch'\n",
    "legends = ['Training', 'Validation']\n",
    "\n",
    "ylim_pad = [0.01, 0.1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot training & validation Accuracy values\n",
    "\n",
    "y1 = history.history['acc']\n",
    "y2 = history.history['val_acc']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[0]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[0]\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Accuracy', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "\n",
    "                         \n",
    "# Plot training & validation loss values\n",
    "    \n",
    "y1 = history.history['loss']\n",
    "y2 = history.history['val_loss']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[1]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[1]\n",
    "    \n",
    "    \n",
    "plt.subplot(122)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Loss', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "                         \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = r\"data/output/models/\"\n",
    "dirs = os.listdir(dir_name)\n",
    "for i in range(len(dirs)):\n",
    "    print(i, dirs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir =dir_name+dirs[0]+\"/\"\n",
    "model_names = os.listdir(cur_dir)\n",
    "for i in range(len(model_names)):\n",
    "    print(i, model_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = cur_dir+model_names[5]\n",
    "\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"results\")\n",
    "result  = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "\n",
    "print(\"%s%.2f  \"% (\"Loss     : \", result[0]))\n",
    "print(\"%s%.2f%s\"% (\"Accuracy : \", result[1]*100, \"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"results\")\n",
    "y_pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)  \n",
    "y_pred = y_pred.argmax(axis=-1)\n",
    "y_true=test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_name_CM = figure_directory+\"/CM\"\n",
    "\n",
    "title = model_file.split(\"/\")\n",
    "model_title = \"/\".join([i for i in title[3:]])\n",
    "\n",
    "precision = precision_score(y_true, y_pred) \n",
    "recall = recall_score(y_true, y_pred) \n",
    "f1 = f1_score(y_true, y_pred) \n",
    "\n",
    "print(\"-\"*90)\n",
    "print(\"Derived Report\")\n",
    "print(\"-\"*90)\n",
    "print(\"%s%.2f%s\"% (\"Precision     : \", precision*100, \"%\"))\n",
    "print(\"%s%.2f%s\"% (\"Recall        : \", recall*100,    \"%\"))\n",
    "print(\"%s%.2f%s\"% (\"F1-Score      : \", f1*100,        \"%\"))\n",
    "print(\"-\"*90)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.title(\"Confusion Matrix for Model File (Test Dataset): \\n\"+model_title, fontsize=11)\n",
    "fig.savefig(image_file_name_CM, dpi=100)\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "cls_report_print = classification_report(y_true, y_pred, target_names=classes)\n",
    "\n",
    "cls_report = classification_report(y_true, y_pred, target_names=classes, output_dict=True)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"-\"*90)\n",
    "print(\"Report for Model File: \", model_title)\n",
    "print(\"-\"*90)\n",
    "print(cls_report_print)\n",
    "print(\"-\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numofbatch = len(test_generator)\n",
    "\n",
    "batch_no = random.randint(0, numofbatch-1)\n",
    "\n",
    "y_img_batch, y_true_batch = test_generator[batch_no] \n",
    "y_true_batch = y_true_batch.argmax(axis=-1)\n",
    "\n",
    "y_pred_batch = model.predict(y_img_batch)\n",
    "y_pred_batch = y_pred_batch.argmax(axis=-1)\n",
    "\n",
    "\n",
    "sizeofbatch = len(y_true_batch)\n",
    "print(\"-\"*35)\n",
    "print(\"%s%d\"%     (\"Selected Batch No       : \", batch_no))\n",
    "print(\"-\"*35)\n",
    "print(\"%s%d\"%     (\"Batch Size              : \", len(y_pred_batch)))\n",
    "print(\"-\"*35)\n",
    "print(\"%s%.2f%s\"% (\"Accuracy                : \", np.mean(y_true==y_pred)*100, \"%\"))\n",
    "print(\"-\"*35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(y_img_batch, y_true, y_pred, subplot_params, plot_params, class_map, testing_dir, image_file_name, count=8, sample=True):\n",
    "    fig, axs = get_fig_axs(subplot_params)\n",
    "    plt.rcParams.update({'axes.titlesize': plot_params[\"axes.titlesize\"]})\n",
    "    plt.subplots_adjust(hspace=subplot_params[\"hspace\"], wspace=subplot_params[\"wspace\"])\n",
    "    \n",
    "    file_names = test_generator.filenames\n",
    "    m = {}\n",
    "    length = len(y_true)\n",
    "    for i in range(0, count): \n",
    "        num = i\n",
    "        if sample:\n",
    "            num = random.randint(0, length-1)\n",
    "            while num in m:\n",
    "                num = int(random.randint(0, length-1))\n",
    "\n",
    "            m[num]=1\n",
    "\n",
    "\n",
    "        plt.subplot(subplot_params[\"nrows\"], subplot_params[\"ncols\"], i+1)\n",
    "        img = cv2.imread(testing_dir+\"\\\\\"+ file_names[num], 1)\n",
    "        plt.imshow(img)\n",
    "\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        \n",
    "        original = class_map[y_true[num]]\n",
    "        predicted = class_map[y_pred[num]]\n",
    "        \n",
    "        \n",
    "        title_text = (\"%s%s%s%s%s\"%(\"True: \", original, \"\\n\", \"Pred: \", predicted))\n",
    "        \n",
    "        if original==predicted:\n",
    "            plt.title(title_text)\n",
    "        else:\n",
    "            plt.title(title_text, color='red')\n",
    "            \n",
    "\n",
    "        if plot_params[\"update_image\"] and os.path.exists(image_file_name):\n",
    "            os.remove(image_file_name)   \n",
    "\n",
    "        fig.savefig(image_file_name, dpi=subplot_params[\"dpi\"])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_name_batch = figure_directory+\"/result\"\n",
    "image_file_name_sample = figure_directory+\"/sample\"\n",
    "\n",
    "batch_size_t = len(y_true_batch)\n",
    "\n",
    "class_map = {v: k for k, v in test_generator.class_indices.items()}\n",
    "\n",
    "\n",
    "dpi=100\n",
    "\n",
    "\n",
    "ncols = 8\n",
    "# ncols = batch_size_t if batch_size_t<ncols else ncols     \n",
    "# nrows = batch_size_t/ncols\n",
    "# nrows = int(batch_size_t/ncols)+1 if batch_size_t%ncols else  int(batch_size_t/ncols)\n",
    "nrows = 4\n",
    "\n",
    "count = ncols*nrows\n",
    "\n",
    "\n",
    "subplot_params = get_reset_subplot_params(nrows, ncols, dpi)\n",
    "plot_params = get_reset_plot_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(y_img_batch, y_true_batch, y_pred_batch, subplot_params, plot_params, class_map, testing_dir, image_file_name_batch, count=count, sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 4\n",
    "nrows = 2\n",
    "\n",
    "if batch_size_t<4:\n",
    "    cols = 1\n",
    "    \n",
    "count = cols*rows\n",
    "    \n",
    "\n",
    "subplot_params = get_reset_subplot_params(nrows, ncols, dpi)\n",
    "plot_params = get_reset_plot_params()\n",
    "\n",
    "\n",
    "show_predictions(y_img_batch, y_true_batch, y_pred_batch, subplot_params, plot_params, class_map, testing_dir, image_file_name_sample, count=count, sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
